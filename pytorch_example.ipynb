{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from collections import OrderedDict\n",
    "from torchvision.models import resnet50, densenet121, inception_v3\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mLICENSE\u001b[0m*              \u001b[01;34macl\u001b[0m/      \u001b[01;34mhemorrhage\u001b[0m/  \u001b[01;34mpneumonia\u001b[0m/              \u001b[01;34mthyroid\u001b[0m/\n",
      "\u001b[01;32mREADME.md\u001b[0m*            \u001b[01;34mbreast\u001b[0m/   \u001b[01;32mhoge.txt\u001b[0m*    \u001b[01;32mpytorch_example.ipynb\u001b[0m*  \u001b[01;34mutil\u001b[0m/\n",
      "\u001b[01;34mRadImageNet_pytorch\u001b[0m/  \u001b[01;34mcovid19\u001b[0m/  \u001b[01;34mmeniscus\u001b[0m/    \u001b[01;34msarscovid2\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'thyroid/dataframe/thyroid_val_fold\"+str(i+1)+\".csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/takaya_workspace/MultiTaskSSL/pytorch_example.ipynb Cell 5\u001b[0m line \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmarianna:container/takaya_workspace/MultiTaskSSL/pytorch_example.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mthyroid/dataframe/thyroid_train_fold1.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmarianna:container/takaya_workspace/MultiTaskSSL/pytorch_example.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df_val \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mthyroid/dataframe/thyroid_val_fold\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+str(i+1)+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmarianna:container/takaya_workspace/MultiTaskSSL/pytorch_example.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m df_test\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mthyroid/dataframe/thyroid_test_fold\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+str(i+1)+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'thyroid/dataframe/thyroid_val_fold\"+str(i+1)+\".csv'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'thyroid/dataframe/thyroid_train_fold1.csv')\n",
    "df_val = pd.read_csv('thyroid/dataframe/thyroid_val_fold\"+str(i+1)+\".csv')\n",
    "df_test= pd.read_csv('thyroid/dataframe/thyroid_test_fold\"+str(i+1)+\".csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label']=df_train['label'].apply(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['label']=df_val['label'].apply(get_label)\n",
    "df_test['label']=df_test['label'].apply(get_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(df_train.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.linear = nn.Linear(2048, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop_out(x)\n",
    "        x = self.linear(x)\n",
    "        #x = torch.softmax(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base_model = resnet50(pretrained=False)\n",
    "        encoder_layers = list(base_model.children())\n",
    "        self.backbone = nn.Sequential(*encoder_layers[:9])\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = Backbone()\n",
    "classifier = Classifier(num_class=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.load_state_dict(torch.load(\"resnet50_torch.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class createDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.dataframe.iloc[index][\"img_dir\"]\n",
    "        image = cv2.imread(image)\n",
    "        image = (image-127.5)*2 / 255\n",
    "        image = cv2.resize(image,(224,224))\n",
    "        #image = np.transpose(image,(2,0,1))   \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        label = self.dataframe.iloc[index][\"label\"]\n",
    "        return {\"image\": image , \"label\": torch.tensor(label, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = createDataset(df_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=20)\n",
    "val_dataset = createDataset(df_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=20)\n",
    "\n",
    "test_dataset = createDataset(df_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,  num_epochs=30, fold_num):\n",
    "    min_valid_loss = np.inf\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        model.train()     # Optional when not using Model Specific layer\n",
    "        for i_batch, info_batch in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = info_batch['image'].to(device, dtype=torch.float), info_batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            target = model(data)\n",
    "            loss = criterion(target,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        model.eval()     # Optional when not using Model Specific layer\n",
    "        for i_batch, info_batch in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = info_batch['image'].to(device, dtype=torch.float), info_batch['label'].to(device)\n",
    "            \n",
    "            target = model(data)\n",
    "            loss = criterion(target,labels)\n",
    "            valid_loss = loss.item() * data.size(0)\n",
    "\n",
    "        print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_loader)} \\t\\t Validation Loss: {valid_loss / len(val_loader)}')\n",
    "        if min_valid_loss > valid_loss:\n",
    "            print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "            min_valid_loss = valid_loss\n",
    "            # Saving State Dict\n",
    "            torch.save(model.state_dict(), 'acl_fold'+str(fold_num)+'_best_model.pth')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.4457762529561808 \t\t Validation Loss: 0.31227233193137427\n",
      "Validation Loss Decreased(inf--->3.434996) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.14679992552027926 \t\t Validation Loss: 0.09849888628179376\n",
      "Validation Loss Decreased(3.434996--->1.083488) \t Saving The Model\n",
      "Epoch 3 \t\t Training Loss: 0.08154763455744475 \t\t Validation Loss: 0.12573414499109442\n",
      "Epoch 4 \t\t Training Loss: 0.062108178586560904 \t\t Validation Loss: 0.25889845327897504\n",
      "Epoch 5 \t\t Training Loss: 0.06391522991675679 \t\t Validation Loss: 0.017163275317712265\n",
      "Validation Loss Decreased(1.083488--->0.188796) \t Saving The Model\n",
      "Epoch 6 \t\t Training Loss: 0.07031963857658051 \t\t Validation Loss: 0.03573957085609436\n",
      "Epoch 7 \t\t Training Loss: 0.06533189754890582 \t\t Validation Loss: 0.18448266116055576\n",
      "Epoch 8 \t\t Training Loss: 0.018094773113741643 \t\t Validation Loss: 0.0021281332116235385\n",
      "Validation Loss Decreased(0.188796--->0.023409) \t Saving The Model\n",
      "Epoch 9 \t\t Training Loss: 0.014920052743616328 \t\t Validation Loss: 0.002436336637897925\n",
      "Epoch 10 \t\t Training Loss: 0.006788608369298834 \t\t Validation Loss: 0.007084378464655442\n",
      "Epoch 11 \t\t Training Loss: 0.0015907104557100155 \t\t Validation Loss: 0.24107835509560324\n",
      "Epoch 12 \t\t Training Loss: 0.0032665943758079913 \t\t Validation Loss: 0.0003260832533917644\n",
      "Validation Loss Decreased(0.023409--->0.003587) \t Saving The Model\n",
      "Epoch 13 \t\t Training Loss: 0.0016831970993675047 \t\t Validation Loss: 0.7905788421630859\n",
      "Epoch 14 \t\t Training Loss: 0.0017326752802416326 \t\t Validation Loss: 0.008139228278940374\n",
      "Epoch 15 \t\t Training Loss: 0.00318281331147863 \t\t Validation Loss: 0.28556355563077057\n",
      "Epoch 16 \t\t Training Loss: 0.007273598028962294 \t\t Validation Loss: 0.4322407895868475\n",
      "Epoch 17 \t\t Training Loss: 0.0029323149308586103 \t\t Validation Loss: 0.6556116884404962\n",
      "Epoch 18 \t\t Training Loss: 0.08122620849541648 \t\t Validation Loss: 0.08495957201177423\n",
      "Epoch 19 \t\t Training Loss: 0.04737511703969686 \t\t Validation Loss: 0.18606922843239523\n",
      "Epoch 20 \t\t Training Loss: 0.0035187961037501316 \t\t Validation Loss: 0.1872019334272905\n",
      "Epoch 21 \t\t Training Loss: 0.0008831469497874752 \t\t Validation Loss: 0.0005289917303757234\n",
      "Epoch 22 \t\t Training Loss: 0.0006706713745106154 \t\t Validation Loss: 0.016736537218093872\n",
      "Epoch 23 \t\t Training Loss: 0.013629328110075402 \t\t Validation Loss: 0.6344210451299493\n",
      "Epoch 24 \t\t Training Loss: 0.023848454354840093 \t\t Validation Loss: 0.444000244140625\n",
      "Epoch 25 \t\t Training Loss: 0.004152694679510455 \t\t Validation Loss: 0.02475080977786671\n",
      "Epoch 26 \t\t Training Loss: 0.00046661380891082146 \t\t Validation Loss: 0.038509940559213814\n",
      "Epoch 27 \t\t Training Loss: 0.11307178725020434 \t\t Validation Loss: 0.7771469463001598\n",
      "Epoch 28 \t\t Training Loss: 0.012336848162074322 \t\t Validation Loss: 0.2670136581767689\n",
      "Epoch 29 \t\t Training Loss: 0.0023676027523314197 \t\t Validation Loss: 0.33774974129416724\n",
      "Epoch 30 \t\t Training Loss: 0.003787129033608525 \t\t Validation Loss: 0.6296653747558594\n"
     ]
    }
   ],
   "source": [
    "for f in range(5):\n",
    "        ###use pretrain RIN-ResNet50 weights\n",
    "        model = nn.Sequential(backbone, classifier)\n",
    "        device = torch.device(\"cuda\")\n",
    "        model = model.to(device)\n",
    "        best_model = train_model(model, criterion,optimizer, fold_num = f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "70862b2a35782cf03f229e4805e6826ca21bf4d4920a510b87654639dd617db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
